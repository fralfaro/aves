# Visualizaci√≥n de Texto

Hasta esta unidad hemos visto diferentes tipos de datasets estructurados. Debido a la estructura y atributos de cada dataset pod√≠amos determinar las marcas y canales efectivas y coherentes al dise√±ar una visualizaci√≥n. En las visualizaciones que hemos conocido, el texto ha estado presente: lo utilizamos para darle nombre a los atributos, y as√≠, por ejemplo, poner una etiqueta en el eje `x`, desplegar el nombre de los nodos en un `node_link_diagram` de una red social, o indicar el nombre de un √°rea geogr√°fica en un `choropleth_map`. Sin embargo, podemos encontrar situaciones en las que el texto no es un atributo explicativo o una anotaci√≥n, sino que es parte de la tarea a realizar. Esta situaci√≥n es frecuente, puesto que pran parte de la informaci√≥n disponible en el mundo es texto.

¬øC√≥mo luce una visualizaci√≥n con texto? La siguiente visualizaci√≥n ([explicada con mayores detalles aqu√≠](https://medium.com/@carnby/every-colour-you-are-stance-prediction-and-turnaround-in-controversial-issues-bac0e956f77e)) muestra un `line_chart` que muestra el volumen de tweets generados en una discusi√≥n durante cuatro a√±os, utilizando notas para explicar eventos relevantes, y marcas de texto para indicar los temas, palabras y otros elementos textuales relevantes para cada a√±o de discusi√≥n:

![Caracterizando per√≠odos de tiempo con el lenguaje asociado a cada a√±o en la discusi√≥n sobre aborto en Twitter. Fuente: Eduardo Graells-Garrido, Ricardo Baeza-Yates, &amp; Mounia Lalmas. Every Colour You Are: Stance Prediction and Turnarounds in Controversial Issues.](http://datagramas.cl/courses/infovis/12_texto/images/abortion_timeline_hu000a7e2c37157755dfb2fe6948e4a79f_917478_660x0_resize_box_3.png)

Caracterizando per√≠odos de tiempo con el lenguaje asociado a cada a√±o en la discusi√≥n sobre aborto en Twitter. Fuente: Eduardo Graells-Garrido, Ricardo Baeza-Yates, & Mounia Lalmas. Every Colour You Are: Stance Prediction and Turnarounds in Controversial Issues.

Cuando el texto es una marca y no una anotaci√≥n nos encontramos con distintos desaf√≠os: su tama√±o depende del largo del texto y de la tipograf√≠a utilizada, tambi√©n puede contener elementos utilizados en el texto pero que no son _textuales_, como emoji (üíö en este caso). En el ejemplo, la posici√≥n en el eje `x` del texto expresa el a√±o que est√° caracterizando, y la posici√≥n en el eje `y` expresa la relevancia que tuvo para ese a√±o. El tama√±o de la tipograf√≠a tambi√©n codifica ese valor. Ahora bien, este ejemplo no define una t√©cnica en particular, porque el principal componente de la visualizaci√≥n sigue siendo un `line_chart`. Podr√≠amos decir que es un `line_chart` contextualizado con una visualizaci√≥n de texto.

As√≠, en esta unidad exploraremos distintas t√©cnicas de visualizaci√≥n de texto. A diferencia de los data sets que hemos visto hasta ahora, el texto no tiene una estructura clara, de hecho, se le considera un tipo de dato **no estructurado**. ¬øC√≥mo es eso posible? Para nosotres, las personas, el texto s√≠ tiene estructura. Podemos identificar letras, palabras, frases, p√°rrafos, documentos ‚Äî elementos que entendemos gracias a la gram√°tica y a la sem√°ntica. Entonces, ¬øpor qu√© decimos que no tiene estructura?

La estructura que vemos en el texto est√° en nuestras mentes y en la estructura comunicacional de la sociedad. _No est√°_ especificada en como se almacena el texto en una m√°quina. En t√©rminos b√°sicos, un documento suele ser almacenado como una larga cadena de car√°cteres, uno detr√°s del otro. Los aspectos estructurales que son comunes en otros tipos de datos no son necesariamente significativos o √∫tiles en el texto. Por ejemplo, en una tabla sabemos que cada fila tiene la misma cantidad de columnas. En un _corpus_ o conjunto de documentos, ¬øtienen todos los documentos la misma cantidad de palabras?¬øSe utilizan las mismas palabras en cada uno de ellos?¬øEst√°n todos en el mismo idioma? Imponer una estructura al texto sin saber lo que queremos hacer con √©l limitar√° los problemas que podemos resolver y las herramientas que podamos utilizar.

Antes de definir c√≥mo almacenaremos o analizaremos un texto o un corpus necesitamos definir los tipos de tareas realizables. Algunos ejemplos de tareas para texto son las siguientes:

*   **Entender** lo que contiene un documento o conjunto de documentos (corpus).
*   **Agrupar** documentos distintos dentro de una misma categor√≠a de acuerdo a su similitud.
*   **Comparar** y medir qu√© diferencia un texto o colecci√≥n de documentos de otro(a).
*   **Medir** la evoluci√≥n en el tiempo de un texto de una colecci√≥n de documentos.
*   **Correlacionar** patrones en el texto con los de otros data sets, por ej., con los de una red social.

Adem√°s de nuestro enfoque basado en tareas, debemos cuestionar la **interpretaci√≥n** y la **confianza** en una visualizaci√≥n de texto. Interpretaci√≥n se refiere a qu√© tan bien las propiedades del modelo son caracterizadas por la visualizaci√≥n. Confianza se refiere a cu√°nto podemos entender el texto debido al modelo. Por ejemplo, si no sabemos si el modelo es adecuado, ¬øes debido al modelo o a la visualizaci√≥n?

Tal como suced√≠a con las tareas para otros datasets, algunas de estas operaciones pueden ser automatizables para ciertos casos de uso, mientras que en otros casos deberemos complementar los resultados de un m√©todo computacional con el conocimiento humano. Por ello, antes de explorar t√©cnicas de visualizaci√≥n, vamos a ver un resumen de estructuras de datos y t√©cnicas computacionales de an√°lisis de texto.

## Estructura de Datos y An√°lisis de Texto 

¬øC√≥mo representar una colecci√≥n de documentos? Para poder visualizar texto necesitamos darles una estructura. No siempre se visualiza el texto directamente, sino que suele utilizarse un modelo de lenguaje, un enfoque para convertir el texto en estructuras que ya conozcamos. Veremos distintos enfoques, desde algunos sencillos (_bag of words_) a otros complejos basados en operaciones matem√°ticas sobre la estructura del texto.

Uno de los enfoques m√°s utilizados, y que de cierto modo es base para casi todos los dem√°s, es _bag of words_ (bolsa de palabras). En este esquema, una colecci√≥n se representa con una matriz: en la imagen, cada columna es un documento, y cada fila es una palabra. Cada celda contiene la frecuencia de la palabra correspondiente a la fila en el documento correspondiente a la columna, es decir, la cantidad de veces que aparece una palabra en un documento:

![Matriz Documentos-T√©rminos, o Document-Term Matrix, correspondiente al enfoque <em>bags of words</em>. Fuente: Wikipedia.](http://datagramas.cl/courses/infovis/12_texto/images/dtm.png)

Matriz Documentos-T√©rminos, o Document-Term Matrix, correspondiente al enfoque _bags of words_. Fuente: Wikipedia.

Un t√©rmino puede ser una palabra, pero tambi√©n puede ser un s√≠mbolo (como los emoji), una expresi√≥n de m√∫ltiples palabras juntas (un _n-grama_). El t√©rmino _bag of words_ le da un significado gen√©rico a _word_ (palabra). Noten que esta representaci√≥n pierde el orden en el que aparecieron las palabras en el documento. De ah√≠ el nombre _bolsa de palabras_: est√°n todas juntas en la bolsa sin un orden espec√≠fico. Llamaremos a esta matriz como `dtm` (_document-term matrix_)

Debemos tener cuidado con el tama√±o de la `dtm`, ya que la cantidad de palabras que tendremos suele ser √≥rdenes de magnitud m√°s grande que la cantidad de documentos. Afortunadamente, la mayor√≠a de los documentos usa una fracci√≥n √≠nfima del total del vocabulario disponible, de modo que la matriz est√° llena de ceros. Este tipo de matriz es conocida como _sparse matrix_ (matriz dispersa) y existen maneras eficientes de almacenarlas.

Al ser una matriz podemos realizar operaciones algebraicas sobre sus filas y columnas, que permiten responder preguntas como el tama√±o de la colecci√≥n, las palabras o documentos con mayor/menor frecuencia, o incluso calcular la similitud entre dos documentos.

Pero, ¬øbasta describir relaciones entre documentos y palabras para entender un corpus? A veces es necesario entender qu√© es lo que contienen los documentos en t√©rminos sem√°nticos. Las t√©cnicas de _[topic modeling](https://en.wikipedia.org/wiki/Topic_model)_ (modelamiento de t√≥picos) buscan identificar los _temas_ o _t√≥picos_ en los documentos de un corpus; algunas de estas t√©cnicas aprovechan la estructura matricial del corpus para hacerlo. Es el caso de _Non-Negative Matrix Factorization_ (`nmf`), o [factorizaci√≥n no-negativa de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_no_negativa_de_matrices). Esta t√©cnica busca descomponer la matrix original `M` (una `dtm`), que contiene `m` documentos (columnas) y `n` palabras (filas), en la multiplicaci√≥n de dos matrices `A x W`, donde `A` es de `n` palabras (filas) y `r` t√≥picos (columnas), y `W` de `r` t√≥picos y `m` documentos, como se ve a continuaci√≥n:

![Diagrama que explica el funcionamiento de Non-Negative Matrix-Factorization. Fuente: S. Arora et al. Building Topic Models Based on Anchor Words.](http://datagramas.cl/courses/infovis/12_texto/images/nmf_hu39a5e5d7faccec7f330fd7d340b4b661_59787_660x0_resize_box_3.png)

Diagrama que explica el funcionamiento de Non-Negative Matrix-Factorization. Fuente: S. Arora et al. Building Topic Models Based on Anchor Words.

Esta descomposici√≥n es posible debido a que todos los elementos de `M` son positivos (`>= 0`). La factorizaci√≥n se define como un problema de optimizaci√≥n, y en s√≠ misma no es un problema de modelamiento de lenguaje, m√°s bien la interpretaci√≥n que se les da a las matrices `A` y `W` se relaciona con lenguaje. La matriz `A` contiene la relaci√≥n entre las palabras del corpus y los t√≥picos, y la matriz `W` contiene la relaci√≥n entre los documentos y los t√≥picos. De esta manera, la relaci√≥n entre un documento y sus palabras (codificada en la matriz `M`) se expresa como la suma de la relaci√≥n entre palabras y t√≥picos, y la relaci√≥n entre t√≥picos y documentos. Ahora bien, ¬øde d√≥nde sale el par√°metro `r`, que define la cantidad de t√≥picos a analizar? Usualmente es un par√°metro especificado por la persona que realiza el modelamiento. No existe una regla que indique el n√∫mero √≥ptimo de temas dentro de un corpus, adem√°s, las relaciones que encuentra este m√©todo son latentes, es decir, obedecen a patrones matem√°ticos dentro de la matriz `M` y no necesariamente a como una persona interpreta el concepto ‚Äút√≥pico‚Äù o ‚Äútema.‚Äù Por ello, la visualizaci√≥n de modelos de t√≥picos es importante, ya que permite entender lo que est√° capturando el modelo e iterar sobre los par√°metros que recibe.

Otra interpretaci√≥n de `nmf` es que realiza una [reducci√≥n dimensional](https://es.wikipedia.org/wiki/Reducci%C3%B3n_de_dimensionalidad), ya que permite expresar tanto palabras como documentos como un vector de menores dimensiones a las originales. Aunque si lo que buscamos es reducir la dimensionalidad de nuestro dataset, existen t√©cnicas mejores y m√°s adecuadas para visualizaci√≥n.

Una de esas t√©cnicas es `umap` (_[Uniform Manifold Approximation and Projection](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection)_). En esencia, es una t√©cnica de reducci√≥n dimensional que considera relaciones complejas entre los elementos del dataset, en contraste con `nmf` que considera que un elemento es la simple suma de sus componentes latentes. Esta t√©cnica se suele utilizar para expresar cada elemento del dataset en 2 o 3 dimensiones, lo que facilita su visualizaci√≥n. Como ejemplo, [esta proyecto](https://homepage.univie.ac.at/noichlm94/posts/structure-of-recent-philosophy-ii/) muestra un corpus de documentos filos√≥ficos, para mostrar ‚Äúla estructura de la filosof√≠a reciente.‚Äù Para ello, primero aplica `umap` sobre la `dtm`, luego un algoritmo de clustering para identificar grupos y finalmente un posicionamiento de etiquetas y anotaciones que puede ser manual. El resultado es el siguiente:

![La estructura de la filosof√≠a. Fuente: Maximilian Noichl.](http://datagramas.cl/courses/infovis/12_texto/images/umap_philosophy_hu7112274127af64a29f2293c5ed658fa5_1239582_660x0_resize_box_3.png)

La estructura de la filosof√≠a. Fuente: Maximilian Noichl.

Es com√∫n utilizar `umap` (o t√©cnicas similares) para presentar una vista global del dataset. Por ejemplo, una persona podr√≠a hacer clic en uno de los clusters de la visualizaci√≥n, y as√≠ entrar a otra vista que muestre los detalles de ese cluster.

Existen modelos m√°s avanzados que s√≠ consideran el orden y las secuencias de palabras. Es un tema que queda para un curso avanzado de Machine Learning o Procesamiento de Lenguaje Natural (NLP). Sin embargo, el resultado de dichos modelos sigue expres√°ndose como vectores o matrices asociadas al texto, y por tanto, algunas de las t√©cnicas de visualizaci√≥n que veremos en esta unidad tambi√©n se pueden aplicar a ellos. Tambi√©n veremos t√©cnicas de visualizaci√≥n que se pueden aplicar a otros aspectos del texto, por ejemplo, a su estructura ling√º√≠stica o a una estructura de red inferida.

## Word Cloud 

Las `word_cloud` surgieron como una manera de navegar por sitios en la (ya) vieja Web 2.0. En ellas, cada palabra en el corpus es una marca cuyo canal de tama√±o es proporcional a su frecuencia. Usualmente el canal de color es aleatorio, y el canal de posici√≥n optimiza el espacio entre las palabras para que sea el menor posible. La siguiente es la `word_cloud` de una canci√≥n recientemente popular en Chile:

![Fing√≠as de Paloma Mami.](http://datagramas.cl/courses/infovis/12_texto/images/word_cloud_hufbf689f9742be3aff2e47a4356114bfd_304896_660x0_resize_box_3.png)

Fing√≠as de Paloma Mami.

Aunque las `word_cloud` son un tipo de visualizaci√≥n popular tienen muchos defectos visibles en la imagen. En funci√≥n de los principios de dise√±o, el canal de √°rea utilizado para graficar la frecuencia dificulta comparaciones, tanto por percepci√≥n como al largo de las palabras. Adem√°s las palabras m√°s frecuentes no son necesariamente informativas. Es posible quitar palabras comunes o frecuentes que no significan nada por s√≠ mismas (como ‚Äúque‚Äù o ‚Äúlo‚Äù), sin embargo, se puede confundir la noci√≥n de volumen (frecuencia) con la de relevancia.

Si la tarea es tener una vista global del vocabulario, una `word_cloud` puede ser un buen punto de partida debido a que permite agrupar muchas palabras en poco espacio. Pueden hacer las suyas en la p√°gina de [Jason Davies](https://www.jasondavies.com/wordcloud/).

Un uso de `word_cloud` es como elemento de navegaci√≥n. El siguiente ejemplo muestra un _data portrait_, concepto acu√±ado por [Judith Donath](http://vivatropolis.com/judith/) que define un retrato generado a partir de los datos de un perfil (en el ejemplo, el m√≠o en Twitter el 2015), donde la `word_cloud` es el principal elemento de navegaci√≥n:

![Data Portraits. ¬øC√≥mo te ves en la Web? Fuente: E. Graells-Garrido, M. Lalmas, R. Baeza-Yates, Data portraits and intermediary topics: Encouraging exploration of politically diverse profiles.](../../images/4-Figure1-1.png)

Data Portraits. ¬øC√≥mo te ves en la Web? Fuente: E. Graells-Garrido, M. Lalmas, R. Baeza-Yates, Data portraits and intermediary topics: Encouraging exploration of politically diverse profiles.

En este ejemplo, el canal de color no es aleatorio, ya que expresa la categor√≠a de cada t√©rmino incluido en la `word_cloud`. Al hacer click en una palabra se muestra el per√≠odo de tiempo en que esa palabra se utiliza, a trav√©s de los colores del `bar_chart` que muestran la frecuencia de _twitteo_ por semana del a√±o. Al mismo tiempo, al hacer clic en una barra del `bar_chart`, se muestran las palabras que se utilizaban en la fecha correspondiente. De esta manera, el _data portrait_ permite explorar el contenido que genera una persona desde una vista tem√°tica y temporal.

## Bubble Clouds 

Una `bubble_cloud` es similar a un `scatter_plot` en tanto las marcas son c√≠rculos (burbujas) posicionadas en el espacio, cuyo canal de tama√±o representa la frecuencia de la palabra correspondiente a la marca. Cada burbuja tiene escrita sobre s√≠ la palabra correspondiente. Esta codificaci√≥n visual resuelve algunas de las limitaciones de las `word_cloud`, y permite incorporar otros atributos en cada marca. Es un gr√°fico agradable est√©ticamente y f√°cil de entender.

El siguiente ejemplo muestra uno de los casos de uso m√°s populares de `bubble_cloud`, donde la posici√≥n en el eje `x` expresaba la asociaci√≥n pol√≠tica de cada palabra utilizada en los discursos de candidatos presidenciales en los Estados Unidos:

![Asociaci√≥n de cada palabra con los partidos pol√≠ticos en los Estados Unidos. Fuente: New York Times.](http://datagramas.cl/courses/infovis/12_texto/images/bubble_cloud_hud166414f9d9f5337b502f0d980280f5f_554724_660x0_resize_box_3.png)

Asociaci√≥n de cada palabra con los partidos pol√≠ticos en los Estados Unidos. Fuente: New York Times.

El uso de colores para mostrar la distribuci√≥n del uso de cada palabra en los dos documentos del corpus (uno representando a Barack Obama y el otro a Mitt Romney) permite entender la sem√°ntica de la posici√≥n de las burbujas, y obtener conocimiento respecto a como cada candidato utiliza un lenguaje distinto para expresarse.

## Parallel Tag Cloud 

Otra variaci√≥n de la `word_cloud` es `parallel_tag_cloud`, una visualizaci√≥n que pone el √©nfasis en las distintas facetas o categor√≠as que tiene un corpus. Las facetas incluyen tem√°ticas, tiempo de publicaci√≥n de los documentos, y otras categor√≠as, que suelen estar predefinidas antes de la visualizaci√≥n. As√≠ luce esta t√©cnica:

![Fuente: C. Collins, F. Vi√®gas, &amp; M. Wattenberg. Parallel tag clouds to explore and analyze faceted text corpora.](http://datagramas.cl/courses/infovis/12_texto/images/parallel_tag_cloud_hu6a878a1970e2b4cb85e521c38ff3aa0b_995438_660x0_resize_box_3.png)

Fuente: C. Collins, F. Vi√®gas, & M. Wattenberg. Parallel tag clouds to explore and analyze faceted text corpora.

Esta visualizaci√≥n muestra para cada faceta la distribuci√≥n de la frecuencia o relevancia de palabras, y al mismo tiempo, c√≥mo esa relevancia var√≠a a lo largo de las facetas. As√≠ podemos entender cuales facetas son similares (o no), y cu√°l es el vocabulario asociado a cada faceta.

## ScatterText 

[ScatterText](https://github.com/JasonKessler/scattertext) es un `scatter_plot` que enfatiza las diferencias entre **dos** documentos (o dos categor√≠as de documentos) respecto a sus t√©rminos m√°s relevantes (¬°no necesariamente los m√°s frecuentes!). Es una herramienta en Python que incluye m√∫ltiples maneras de calcular dicha relevancia. El l√≠mite de dos documentos est√° dado por la codificaci√≥n visual, basada en un eje vertical y otro horizontal. La visualizaci√≥n luce as√≠:

![Una visualizaci√≥n de Scattertext es un scatterplot con texto. Fuente: Jason Kessler, Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ.](http://datagramas.cl/courses/infovis/12_texto/images/scattertext_hu78eb71aac4fc53f88022391f89731bac_552375_660x0_resize_box_3.png)

Una visualizaci√≥n de Scattertext es un scatterplot con texto. Fuente: Jason Kessler, Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ.

En el ejemplo, el eje `y` codifica la asociaci√≥n en el vocabulario de un corpus de pol√≠tica hacia hombres y mujeres, y el eje `x` hacia republicanos y dem√≥cratas en los Estados Unidos. As√≠, esta t√©cnica nos muestra que es posible aprovechar visualizaciones existentes para realizar tareas con texto.

## Shifterator 

[Shifterator](https://shifterator.readthedocs.io/en/latest/) es otra herramienta que visualiza diferencias entre dos textos, esta vez utilizando dos `stacked_bar_chart` como base, uno por cada documento. Al igual que ScatterText, se basa en una bater√≠a de c√°lculos de relevancia, que denomina `word_shifts`, y que se pueden calcular en funci√≥n del sentimiento de las palabras y del per√≠odo en que se utilizan, y que son asociados de manera positiva o negative en su aporte a cada documento. Luce as√≠:

![Shifterator que compara los discursos de dos presidentes de Estados Unidos.](http://datagramas.cl/courses/infovis/12_texto/images/shifterator_hu9103720f6630bb055cfd3ac8beeead6e_312007_660x0_resize_box_3.png)

Shifterator que compara los discursos de dos presidentes de Estados Unidos.

El eje `y` permite expresar la importancia de las palabras (m√°s importante, m√°s arriba) y la direcci√≥n de cada barra permite expresar su contribuci√≥n o relevancia para cada documento. El color de cada barra expresa el tipo de asociatividad. De este modo, esta t√©cnica permite determinar r√°pidamente qu√© y c√≥mo se caracterizan dos documentos (tambi√©n podr√≠an ser dos facetas) de un corpus.

## LDA Vis 

Como comentamos antes, cuando se realiza _topic modeling_ de una colecci√≥n se vuelve necesario visualizar los t√≥picos. El software [pyLDAvis](https://github.com/bmabey/pyLDAvis) utiliza una visualizaci√≥n interactiva compuesta de un `scatter_plot` y un `stacked_bar_chart` para que podamos explorar el espacio de _topics_ de un corpus. El sistema recibe su nombre de la t√©cnica de topic modeling `lda` (_[Latent Dirichlet Allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)_), pero tambi√©n es compatible con `nmf`. El sistema luce as√≠:

![LDAVIS, un sistema para visualizar t√≥picos. Fuente: C. Sievert &amp; K. Shirley. LDAvis: A method for visualizing and interpreting topics.](http://datagramas.cl/courses/infovis/12_texto/images/lda_vis_hu218a93a99613eecfe729fc6670861ce2_202354_660x0_resize_box_3.png)

LDAVIS, un sistema para visualizar t√≥picos. Fuente: C. Sievert & K. Shirley. LDAvis: A method for visualizing and interpreting topics.

Observamos a la derecha el `scatter_plot` que muestra cada t√≥pico como una burbuja, con una posici√≥n calculada utilizando reducci√≥n dimensional. Esto permite saber cu√°les t√≥picos se parecen (porque est√°n cerca en el gr√°fico). Al hacer clic en una burbuja, el gr√°fico a la izquierda se actualiza para mostrar los t√©rminos asociados a ese t√≥pico. Ese gr√°fico es un `stacked_bar_chart` que muestra la distribuci√≥n de frecuencia de t√©rminos asociados al t√≥pico (barras rojas) y la distribuci√≥n de esos mismos t√©rminos en el corpus completo (barras grises). Esta interactividad permite explorar todos los t√≥picos, y determinar si es necesario agregar m√°s t√≥picos (porque algunos presenten temas mezclados entre s√≠) o reducirlos (porque algunos puedan ser redundantes, o contener ruido).

## Topic Competition

Como vimos en `parallel_tag_cloud`, una colecci√≥n de documentos no es est√°tica, ya que puede tener facetas de tiempo. Por tanto, sus t√≥picos tampoco son est√°ticos: cada t√≥pico puede tener su propio comportamiento temporal.

Para entender las din√°micas de los t√≥picos, la visualizaci√≥n `topic_competition` utiliza m√∫ltiples `streamgraph` para mostrar la evoluci√≥n temporal de cada t√≥pico. Debido a que el comportaimento de los t√≥picos puede ser complejo, estas visualizaciones son apoyadas por algoritmos que calculan los flujos del `streamgraph` de manera que se crucen lo menos posible y que se pueda comprender el contenido de cada uno. Dicho contenido se presenta con visualizaciones incrustadas como `word_cloud`, as√≠:

![Evoluci√≥n de los temas de una colecci√≥n en el tiempo. Fuente: P. Xu et al. Visual analysis of topic competition on social media.](http://datagramas.cl/courses/infovis/12_texto/images/topic_competition_hu50853d9f5f73cb1df347e042be15fae5_249116_660x0_resize_box_3.png)

Evoluci√≥n de los temas de una colecci√≥n en el tiempo. Fuente: P. Xu et al. Visual analysis of topic competition on social media.

Visualizaciones como `topic_competition` son √∫tiles sobretodo para humanidades digitales y periodismo de datos, ya que permiten analizar como distintos fen√≥menos basados en texto evolucionan en el tiempo.

## Phrase Nets 

Otro enfoque de ver estructura en el texto es utilizar patrones basados en sintaxis. Por ejemplo, podr√≠amos revisar todas las instancias en que aparece un texto del estilo ‚Äú`A` y `B`‚Äù, y cada `A` y cada `B` que cumpla con ese patr√≥n es considerado como un par de nodos conectado en una red. Como tal, es una red que puede ser visualizada utilizando un `node_link_diagram`. Esta visualizaci√≥n existe y se llama `phrase_net`. El siguiente es un ejemplo del patr√≥n ‚Äú`X` is `Y`‚Äù aplicado al texto de la novela Orgullo y Prejuicio (en su edici√≥n original en ingl√©s):

![Una Phrase Net de Orgullo y Prejuicio. Fuente: F. Van Ham, M. Wattenberg, &amp; F. Vi√®gas. Mapping text with phrase nets.](http://datagramas.cl/courses/infovis/12_texto/images/phrase_nets_hu2b98d6f52019ddb5e87370a2075bf448_469298_660x0_resize_box_3.png)

Una Phrase Net de Orgullo y Prejuicio. Fuente: F. Van Ham, M. Wattenberg, & F. Vi√®gas. Mapping text with phrase nets.

A diferencia del `node_link_diagram` t√≠pico, aqu√≠ utilizamos palabras como marcas, de manera similar a las `word_cloud`. Ahora bien, en la red observamos comunidades tanto de personajes que son mencionados juntas (como Jane y Elizabeth) como de sentimientos (pride and vanity, regret and vexation) y de acciones (play and sing). Si quisieramos conocer la estructura de relaciones en la novela, este tipo de visualizaci√≥n permite responder preguntas sobre la topolog√≠a de dicha red. Ahora bien, hace falta definir un patr√≥n m√°s completo que ‚Äú`X` is `Y`‚Äù para que la red sea exhaustiva.

## Evoluci√≥n y Cambios: History Flow 

Adem√°s de las facetas del texto (como la fecha de publicaci√≥n), existen otros atributos relevantes. Por ejemplo, el historial de modificaci√≥n de un documento - particularmente si es escrito por m√°s de una persona. El sistema `history_flow` permite ver el proceso de escritura y construcci√≥n de los art√≠culos de Wikipedia, tanto a nivel temporal (cu√°ndo se agreg√≥ o quit√≥ contenido) como autoral (qui√©n agreg√≥ o quit√≥ contenido). El sistema utiliza un `stacked_area_chart` donde cada autor(a) es expresada en una de las √°reas de la visualizaci√≥n. Luce as√≠:

![Evoluci√≥n de un art√≠culo en Wikipedia visto por History Flow. Fuente: F. Vi√©gas, M. Wattenberg, K. Dave, Studying cooperation and conflict between authors with history flow visualizations.](http://datagramas.cl/courses/infovis/12_texto/images/history_flow_hud387c83ead0dd6a62d48b982d50c0ff7_3784208_660x0_resize_box_3.png)

Evoluci√≥n de un art√≠culo en Wikipedia visto por History Flow. Fuente: F. Vi√©gas, M. Wattenberg, K. Dave, Studying cooperation and conflict between authors with history flow visualizations.

Este tipo de visualizaci√≥n permite conocer como un tema en Wikipedia evoluciona con el tiempo, es decir, descubrir cu√°ndo el tema se volvi√≥ relevante, cu√°ndo fue pol√©mico, cu√°ndo despert√≥ el inter√©s del p√∫blico general y cu√°nto dur√≥ ese inter√©s ‚Äî algo √∫til para correlacionar con datos hist√≥ricos, como eventos legislativos, de modo de entender el efecto de eventos noticiosos o pol√≠ticos en la percepci√≥n de las personas sobre el tema, que en el caso del ejemplo, es pol√©mico: el aborto.

## Notabilia 

[Notabilia](http://notabilia.net/) es una visualizaci√≥n org√°nica que muestra los procesos de edici√≥n en Wikipedia desde el conflicto: se focaliza en los art√≠culos que son marcados para eliminaci√≥n. Cada art√≠culo es una l√≠nea cuya trayectoria se forma a medida que la discusi√≥n decide si el art√≠culo se elimina o se mantiene en la enciclopedia. La codificaci√≥n visual de esta visualizaci√≥n utiliza una polil√≠nea por cada art√≠culo, cuyo trazado est√° influenciado por las decisiones que toman les editores en el tiempo. Si el art√≠culo recibe votos de mantenci√≥n, se suma un segmento verde, hacia la izquierda. Si recibe votos de eliminaci√≥n, se suma un segmento rojo, hacia la derecha. Eso m√°s algo de aleatoriedad para darle una apariencia org√°nica, similar a un √°rbol. Se ve as√≠:

![Notabilia, ¬øqu√© p√°ginas en Wikipedia sobreviven al criterio de les editores? Fuente: Moritz Stefaner, Dario Taraborelli &amp; Giovanni Luca Ciampaglia.](http://datagramas.cl/courses/infovis/12_texto/images/notabilia_hu30adaf0f8438fe288676e199040c30e6_398668_660x0_resize_box_3.png)

Notabilia, ¬øqu√© p√°ginas en Wikipedia sobreviven al criterio de les editores? Fuente: Moritz Stefaner, Dario Taraborelli & Giovanni Luca Ciampaglia.

El consenso (o la falta de √©ste) es expresado en la visualizaci√≥n.

## Organic Visualization of Document Evolution 

La evoluci√≥n mostrada en las visualizaciones anteriores trabaja con _versiones_ de un texto. Sin embargo, no todo el texto es versionado, y el versionamiento no tiene la capacidad de capturar el proceso mental de la escritura, que es m√°s bien expresado en cada uno de los cambios at√≥micos que hacemos en el texto, construido tecleo a tecleo, con cambios de posiciones del cursor. La siguiente visualizaci√≥n propone visualizar ese proceso utilizando la met√°fora de un √°rbol de eventos, donde la marca es un conjunto de polil√≠neas (las ramas), que contienen secuencias de eventos. Cuando hay una bifurcaci√≥n en el texto, como puede ser un cambio de posici√≥n o la eliminaci√≥n de una secci√≥n, se crean ramas nuevas. La visualizaci√≥n se ve as√≠:

![Visualizaci√≥n org√°nica de la evoluci√≥n de un texto. Fuente: Ignacio P√©rez-Messina, Claudio Guti√©rrez, Eduardo Graells-Garrido, Organic Visualization of Document Evolution.](http://datagramas.cl/courses/infovis/12_texto/images/organic_document_evolution_hu70b40e32d3ea1418c61603a26b6bc507_1188950_660x0_resize_box_3.png)

Visualizaci√≥n org√°nica de la evoluci√≥n de un texto. Fuente: Ignacio P√©rez-Messina, Claudio Guti√©rrez, Eduardo Graells-Garrido, Organic Visualization of Document Evolution.

El ejemplo visualiza el proceso de escritura de un informe universitario registrado en _Google Docs_. La visualizaci√≥n expresa como el texto se va estructurando a medida que se escribe. Al incluir incluso el texto que fue eliminado del documento final, queda de manifiesto que hasta lo borrado deja una huella en el resultado.

## Conclusiones

En esta unidad hemos revisado algunas visualizaciones de texto conocidas. Nos hemos dado cuenta que en su mayor√≠a utilizan las codificaciones visuales que hemos visto en las unidades anteriores, pero teniendo un paso extra que permite darle al texto la estructura necesaria para poder ser visualizado, ya que en s√≠ mismo el texto no tiene una estructura definida como s√≠ la tienen los otros datasets. En un curso de visualizaci√≥n avanzado estas visualizaciones se profundizar√≠an en funci√≥n de las tareas que realizan y de como se eval√∫an sus resultados.

Existen otras √°reas en las cuales tambi√©n se usa texto. Una de ellas es la secuenciaci√≥n gen√©tica. Sin embargo, all√≠ el texto es visto como s√≠mbolo m√°s que como un tipo de dato no estructurado, por ello, lo hemos dejado fuera de esta unidad.

## Lecturas Recomendadas 

*   [Text Analysis with Visualization](http://searchuserinterfaces.com/book/sui_ch11_text_analysis_visualization.html)\_, cap√≠tulo del libro _Search User Interfaces_ de Marti Hearst.
*   [Text Visualization Browser](http://textvis.lnu.se/)\_, una colecci√≥n de v√≠nculos e im√°genes de visualizaci√≥n de texto.
*   Van Ham, F., Wattenberg, M., & Vi√©gas, F. B. (2009). Mapping text with phrase nets._IEEE transactions on visualization and computer graphics_, 15 (6).
*   Collins, Christopher, Fernanda B. Viegas, and Martin Wattenberg (2009). [Parallel tag clouds to explore and analyze faceted text corpora](http://vialab.science.uoit.ca/wp-content/papercite-data/pdf/col2009b.pdf). In _IEEE Symposium on Visual Analytics Science and Technology_.